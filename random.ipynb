{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a \"genetic\" algorithm for chatbot personalization\n",
    "\n",
    "This is important for a number of reasons outlined in our paper *paper*. The way we achieve this is\n",
    "\n",
    "1. Collect responses and their internal representations according to some prompt\n",
    "2. Have the model rank responses and sample from this lineup (maybe with some randomness)\n",
    "3. Create control vectors and update the model\n",
    "4. Repeat this process with the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelforCausalLM, GenerationConfig\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"sarahpann/political-spectrum-questionnaire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: tokenizer(x, truncate=False, padding=False, return_tensors='pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelforCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-hf\",\n",
    "                                             dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we move onto step 1. Let's write all of this information to a json file with serial numbers. The format should go something like:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"idx\": [0, 1, ..., n],\n",
    "    \"question\": [\"blah blah\", ..., \"blah blah\"],\n",
    "    \"response\": [\"blah blah\", ..., \"blah blah\"],\n",
    "    \"representation\": [[0.23812, ...], [0.239841, ...]]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_config = GenerationConfig.from_pretrained(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "for example in dataset['right_dataset']:\n",
    "    out = model.generate(example['original_questions'], output_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so this formattting thing didn't really work... so here's what I came up with instead!\n",
    "\n",
    "```\n",
    "    json_data = [\n",
    "        {\"question_id\": 1, stance: \"left\", \"response\": 1, \"response\": \"I am a leftist because I believe in the redistribution of wealth...\"},\n",
    "        {\"question_id\": 1, stance: \"left\", \"response\": 1,  \"response\": \"I am a rightist because I believe in the free market...\"}, ...\n",
    "    ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_jsonl = []\n",
    "test_jsonl.append({\"input\": \"What is your opinion on the current state of the economy?\", \"output\": \"I think the economy is doing well.\"})\n",
    "test_jsonl.append({\"input\": \"What is your opinion on the current state of the economy?\", \"output\": \"I think the economy is doing well.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open('test.jsonl', 'w') as writer:\n",
    "    writer.write_all(test_jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
